{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classical Neural Networks in Computer Vision\n",
    "==============================\n",
    "对了，这个先写上，计算feature map:\n",
    "    $$ Up=\\frac{Bottom-KernelSize+2*padding}{Stride}+1$$\n",
    "\n",
    "-------------------------------------------------------------\n",
    "\n",
    "1. LeNet\n",
    "----------------------\n",
    "The beginning啊. 很多教材讲解deep learning都是用的这个例子。所用的手写数据库MNIST也是deep learning的入门。   \n",
    "* lecun男神的网页 http://yann.lecun.com/exdb/lenet/  \n",
    "* 3D visualization(trongly recommended): http://scs.ryerson.ca/~aharley/vis/conv/ 可以看每一步，每一层是怎样计算的。  \n",
    "* 和theano代码实现：http://deeplearning.net/tutorial/lenet.html 每次看motivation都觉得人类真是好赞。  \n",
    "%TO DO%（什么时候有空了也跟着实现以下，顺便学下theano) \n",
    "\n",
    "> LeNet architectures:  \n",
    "![LeNet](./images/LeNet.png)\n",
    "\n",
    "经典的 conv pooling fully-connection\n",
    "\n",
    "\n",
    "\n",
    "2. AlexNet\n",
    "----------------------\n",
    "Hinton男神的得意弟子Alex弄出来的，ImageNet 2012 图像分类challenge冠军。拉开了deep learning帷幕。牛逼坏了~  \n",
    "现在各大frameworks的入门例子基本都是这个网络。(我这个字体怎么有点奇怪）  \n",
    "* paper:http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks  \n",
    "* implementation: github搜..一大堆一大堆\n",
    "\n",
    "> AlexNet architectures:  \n",
    "![GitHub Logo](./images/AlexNet.jpg)\n",
    "\n",
    "比LeNet增加有 Normalization 和 Dropout, 嗯哼 %TO DO% 还要找时间来好好整理下这些牛逼的layers  \n",
    "共8层  \n",
    "输入要求256(图像大小)，均值是256的，减均值后再crop到227(网络是224..但caffe这些实现中都是227,我也不太明白）\n",
    "\n",
    "\n",
    "3. VGGNet\n",
    "----------------------\n",
    "ILSVRC 2014 定位第一，分类第二。和AlexNet很像：5个group的卷积，2层fc图像特征，1层fc分类特征。8个part.  \n",
    "所有conv layer使用同样大小的 conv filter：3x3  \n",
    "* paper:https://arxiv.org/pdf/1409.1556.pdf\n",
    "* implementation: 一样的..github搜一大堆一大堆\n",
    "\n",
    "> VGGNet architectures:  \n",
    "![VGGNet](./images/VGGNet.png)\n",
    "\n",
    "\n",
    "恩。。我的经验是，VGG经常作为pre-trained网络，再在后面自定义。比如FCN等..  \n",
    "有VGG16-19  \n",
    "输入要求256(图像大小)，均值是256的，减均值后再crop到224(输入图像大小)\n",
    "\n",
    "  \n",
    "  \n",
    "*这里断一下，我之前实习的导师说，我们至少应该熟记这三个最简单基础的网络，有多少层，每一层是什么，kernel size 多大。  \n",
    "为什么这几个网络能work, 为什么在后来deep learning发展那么快，有些许多性能很好的net,这几个也还是被经常使用。  \n",
    "最经典的conv,pooling,fc, 为什么要用这些层，为什么之后的一些网络经常舍弃fc和conv.  \n",
    "在这里用到的bn,dropout层为什么那么有用，在之后的网络中都经常会使用.同时，什么场合适合使用balabala...  \n",
    "总之，to think how these 牛人们 think out of these 牛逼的 networks. We may become someone like them.  \n",
    "哈哈 :-D*  \n",
    "\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "4. GoogleNet\n",
    "----------------------\n",
    "google出品啊，ILSVRC 2014 分类和检测冠军。  \n",
    "主要是这个 Inception结构 从v1到v4\n",
    "> The main idea of the Inception architecture is to consider\n",
    "how an optimal local sparse structure of a convolutional vision\n",
    "network can be approximated and covered by readily\n",
    "available dense components.   \n",
    "\n",
    "不过要理解inception先得懂1x1 convolutions  \n",
    "推荐视频：https://classroom.udacity.com/courses/ud730/lessons/6377263405/concepts/63713420390923# google工程师讲的，哈哈. 不过看lecture不做笔记都全忘了（捂脸）\n",
    "\n",
    "* paper:  \n",
    "[v1] Going Deeper with Convolutions, 6.67% test error, http://arxiv.org/abs/1409.4842  \n",
    "[v2] Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, 4.8% test error, http://arxiv.org/abs/1502.03167  \n",
    "[v3] Rethinking the Inception Architecture for Computer Vision, 3.5% test error,  http://arxiv.org/abs/1512.00567  \n",
    "[v4] Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, 3.08% test error, http://arxiv.org/abs/1602.07261  \n",
    "\n",
    "* blog:http://blog.csdn.net/u010025211/article/details/51206237  \n",
    "> Inception architectures(V1):\n",
    "![Inception_V4](./images/Inception_V4.jpg)\n",
    "\n",
    "全部v1结构：http://www-gageet-com-static.smartgslb.com/wp-content/uploads/2014/09/googlenet.jpg   \n",
    "面试中可能会问到的问题（因为我被问到过，嘻嘻）：googlenet和vggnet一般哪个需要内存多？model哪个大？为啥？\n",
    "\n",
    "\n",
    "5. Residual Net \n",
    "---------------------------\n",
    "~~kaiming男神的啊，有点累了，明天再看--2016/11/22~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
